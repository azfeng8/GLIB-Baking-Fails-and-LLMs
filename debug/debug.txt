Bugs log:

1/16/23

#TODO: removepanfromoven is not getting picked up. Saw bakesouffle get picked up, then dropeed. In general, if LNDR has an op that the LLM doesn't have, it should be returned from the operator search.
    # Problem how computing LEAP_score: lambda was too small

1/17/23

#TODO: investigate the uncovered transitions: several with "mix", "cleanpan": shouldn't LNDR pick them up?
 # Large amount of no-op data is causing the NDRs to be learned badly (learn NDRs with no effects). Checked LNDR code, ran debug at the bottom of ZPK file.

1/20/23

Implemented final touches on trajectory sampling.

Caught and fixed at least one bug, in parsing.

Ran LNDR through once. Discovered parsing bugs:
  Discovered bug from not parsing negative preconditions and effects.
  Scoped fix to implement: rewrite the parsing + syntax correction.

1/22/23

- Debugged the LLM parsing. Tested on the cached LLM responses for Baking domain. Will leave "OR" and "FORALL" parsing for later (need to check operator search and LNDR handle it, or if need to translate them)
- Debugged the operator search score function. Cleanpan is picked up correctly.
- Current method good for situations where there is not enough no-op data for the learner to predict the operators well, so LLM can extrapolate from the data.
- Investigated LNDR's behavior between recorded iterations 1200 and 1500 (experiment1). Within 20 iterations, cleanpan is overwritten.
- Tried LNDR where if transition is no-op, don't give LNDR the data: 0 success rate, so no-ops are important data.

The next extension: to direct exploration to the precondtions of newly accepted operators to collect less no-op data to convince the learner.
- Randomly sample the conjunction of preconditions as a goal and the action as the (goal, action) tuple. Once this is achieved, the novelty measure should take care of sampling other goals instead.
- Have a shared set between curiosity and learning to add the newly updated operators from learning.

1/23/23

- Implemented two versions of the precondition targeting from GLIB-G1 (commit 87e597c3073dfbfcd374cbcc718cfbba3db6e82a and the commit after it).
  - Just aim for the LLM preconditions as they are.
  - Combine the LLM preconditions with the learner's preconditions of a similar operator (randomly selected among the operators with same action predicate).
- Ran several experiments on Baking domain: strategy is to:
  - target the preconditions of good LLM proposed operators combined with currently learned preconditions.
  - use the good LLM proposed operators for planning until the learner gets more data about the action.
- Caught and resolved 3 bugs.
- Next: Try strategy to target the (preconditions, action) of several learned operators, prioritizing operators with actions that have a lot of no-ops (LLM+GLIB_G1 and LNDR).